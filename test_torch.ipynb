{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "cuda:0\n",
      "tensor([[0.5244, 0.8491, 1.2822],\n",
      "        [1.3184, 1.1992, 0.8613],\n",
      "        [1.6533, 0.6348, 1.5820]], device='cuda:0', dtype=torch.float16)\n",
      "tensor([[0.0681, 0.1674, 0.3958],\n",
      "        [0.3848, 0.3474, 0.0166],\n",
      "        [0.6572, 0.0561, 0.6079]], device='cuda:0', dtype=torch.float16)\n",
      "tensor([[1.0547, 0.4082, 1.0137],\n",
      "        [0.7485, 0.4849, 0.9429],\n",
      "        [1.5391, 0.5640, 1.5615]], device='cuda:0', dtype=torch.float16)\n",
      "tensor(0.2881, device='cuda:0', dtype=torch.float16)\n",
      "tensor([0.2881, 0.5381, 0.5176], device='cuda:0', dtype=torch.float16)\n",
      "tensor([0.2881, 0.4355, 0.6646], device='cuda:0', dtype=torch.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2881],\n",
       "        [0.5381],\n",
       "        [0.5176],\n",
       "        [0.4355],\n",
       "        [0.7090],\n",
       "        [0.0197],\n",
       "        [0.6646],\n",
       "        [0.5288],\n",
       "        [0.9253]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.rand(3, 3, device=device,  dtype=torch.float16)\n",
    "\n",
    "print(t1.size())\n",
    "print(t1.device)\n",
    "\n",
    "t2 = torch.rand(3, 3, device=device,  dtype=torch.float16)\n",
    "\n",
    "# Element-wise\n",
    "print(t1 + t2)\n",
    "print(t1 * t2)\n",
    "\n",
    "# Matrix multiplication\n",
    "print(t1 @ t2)\n",
    "\n",
    "# Slicing\n",
    "print(t1[0, 0])\n",
    "print(t1[0, :])\n",
    "print(t1[:, 0])\n",
    "\n",
    "t1.view(-1, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Tensors + NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1.], dtype=float32),\n",
       " array([1., 1., 1., 1., 1.]),\n",
       " tensor([1., 1., 1., 1., 1.], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()  # Pointer to the same memory!\n",
    "\n",
    "c = np.ones(5)\n",
    "d = torch.from_numpy(c)  # Pointer to the same memory, again!\n",
    "\n",
    "d = d.to(device)  # Move to GPU\n",
    "\n",
    "a, b, c, d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch AutoGrad\n",
    "\n",
    "Theoretical:\n",
    "\n",
    "* Jacobian Matrix, Chain Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0305, 1.5738, 1.7052])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x + 2\n",
    "z = y * y * 2\n",
    "z = z.mean()\n",
    "\n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward()  # dz/dx, pass v to multiply by the gradient\n",
    "\n",
    "# Prevent gradient tracking\n",
    "# x.requires_grad_(False)\n",
    "# y = x.detach()\n",
    "# with torch.no_grad():\n",
    "#     pass\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_output = (weights * 3).sum()\n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "    \n",
    "    # Clean the gradient\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "Chain Rule:\n",
    "\n",
    "$$\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial y} * \\frac{\\partial y}{\\partial x}$$\n",
    "\n",
    "Computational Graph:\n",
    "\n",
    "* Graph is created and updated on every operation\n",
    "* Allows the calculation of local gradients\n",
    "* Calculate loss:\n",
    "\n",
    "$$\\frac{\\partial Loss}{\\partial x} = \\frac{\\partial Loss}{\\partial z} * \\frac{\\partial z}{\\partial x}$$\n",
    "\n",
    "Steps: \n",
    "1. Forward pass: Calculate loss\n",
    "2. Compute local gradients\n",
    "3. Backward pass: Calculate dLoss/dWeights using chain rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:\t\t tensor(1., grad_fn=<PowBackward0>)\n",
      "Gradient:\t tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# Forward pass and compute the loss\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y) ** 2\n",
    "\n",
    "print(\"Loss:\\t\\t\", loss)\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "print(\"Gradient:\\t\", w.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent using Autograd\n",
    "\n",
    "Training pipeline:\n",
    "1. Design model (input, output size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop\n",
    "    * Forward pass: compute prediction\n",
    "    * Backward pass: gradients\n",
    "    * Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = -1.418\n",
      "Epoch 50: w = 1.822, loss = 0.04695665\n",
      "Epoch 100: w = 1.916, loss = 0.01039116\n",
      "Epoch 150: w = 1.961, loss = 0.00229950\n",
      "Epoch 200: w = 1.982, loss = 0.00050886\n",
      "Epoch 250: w = 1.991, loss = 0.00011260\n",
      "Epoch 300: w = 1.996, loss = 0.00002492\n",
      "Epoch 350: w = 1.998, loss = 0.00000551\n",
      "Epoch 400: w = 1.999, loss = 0.00000122\n",
      "Epoch 450: w = 2.000, loss = 0.00000027\n",
      "Epoch 500: w = 2.000, loss = 0.00000006\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction, manually\n",
    "# def forward(x):\n",
    "#     return w * x\n",
    "\n",
    "# loss (MSE), manually\n",
    "# def loss(y, y_predicted):\n",
    "#     return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# gradient, manually\n",
    "# MSE = 1/n * (w*x - y) ** 2\n",
    "# dJ/dw = 1/n ex (w*x - y)\n",
    "# def gradient(x, y, y_predicted):\n",
    "#     return np.dot(2*x, y_predicted-y) / len(x)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, ouput_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, ouput_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "print(f\"Prediction before training: f(5) = {model(X_test).item():.3f}\")\n",
    "\n",
    "learning_rate = 0.05\n",
    "n_iters = 500\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients manually\n",
    "    # dw = gradient(X, Y, y_pred)\n",
    "    \n",
    "    # gradient = backward pass\n",
    "    l.backward()\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "        \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1) % (n_iters / 10) == 0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f\"Epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}\")\n",
    "\n",
    "print(f\"Prediction after training: f(5) = {model(X_test).item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss = 4327.0513\n",
      "Epoch: 20, loss = 3231.5046\n",
      "Epoch: 30, loss = 2438.1963\n",
      "Epoch: 40, loss = 1863.1646\n",
      "Epoch: 50, loss = 1445.9622\n",
      "Epoch: 60, loss = 1143.0083\n",
      "Epoch: 70, loss = 922.8420\n",
      "Epoch: 80, loss = 762.7228\n",
      "Epoch: 90, loss = 646.1957\n",
      "Epoch: 100, loss = 561.3403\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare Data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# Model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# Loss, Optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training Loop\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # Forward pass, loss\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch: {epoch+1}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "# Plot\n",
    "predicted = model(X).detach().numpy()\n",
    "\n",
    "sns.set()\n",
    "plt.plot(X_numpy, y_numpy, \"ro\")\n",
    "plt.plot(X_numpy, predicted, \"b\")\n",
    "plt.title(\"PyTorch Linear Regression Example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss = 0.6563\n",
      "Epoch: 20, loss = 0.5401\n",
      "Epoch: 30, loss = 0.4665\n",
      "Epoch: 40, loss = 0.4152\n",
      "Epoch: 50, loss = 0.3772\n",
      "Epoch: 60, loss = 0.3475\n",
      "Epoch: 70, loss = 0.3235\n",
      "Epoch: 80, loss = 0.3037\n",
      "Epoch: 90, loss = 0.2869\n",
      "Epoch: 100, loss = 0.2725\n",
      "Accuracy = 0.9035\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "    \n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# Loss, Optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # Forward pass, loss\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Updates\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch: {epoch+1}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred_classes = y_pred.round()\n",
    "    acc = y_pred_classes.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f\"Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets, Data Loader\n",
    "\n",
    "Terminology:\n",
    "\n",
    "* epoch = 1 forward and backward pass of all training samples\n",
    "* batch_size = number of training samples in one forward & backward pass\n",
    "* number of iterations = number of passes, each pass using [batch_size] number of samples\n",
    "\n",
    "e.g. 100 samples, batch_size=20 -> 100/20 = 5 iterations for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
      "Epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
      "Epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
      "Epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
      "Epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
      "Epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
      "Epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
      "Epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
      "Epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
      "Epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
      "Epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
      "Epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
      "Epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
      "Epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
      "Epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
      "Epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
      "Epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
      "Epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform=None):\n",
    "        xy = np.loadtxt(\"data/wine/wine.csv\", delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        \n",
    "        self.x = xy[:, 1:]\n",
    "        self.y = xy[:, [0]]\n",
    "        \n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "    \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "\n",
    "class ToTensor:\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "    \n",
    "class MulTransform:\n",
    "    \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, target\n",
    "\n",
    "    \n",
    "dataset = WineDataset()\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "n_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iters = math.ceil(total_samples/4)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward backward update\n",
    "        \n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}, step {i+1}/{n_iters}, inputs {inputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
      "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
      "        4.2600e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# dataset = torchvision.datasets.MNIST(root=\"./data\", transform=torchvision.transforms.ToTensor())\n",
    "dataset = WineDataset(transform=None)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax & Cross-Entropy\n",
    "\n",
    "**Softmax**:\n",
    "\n",
    "$$\n",
    "S(y_i) = \\frac{e^{y_i}}{\\sum e^{y_i}} \n",
    "$$\n",
    "\n",
    "**Cross-Entropy**:\n",
    "\n",
    "$$\n",
    "D(\\hat Y, Y) = - \\frac{1}{n} \\sum Y_i * log(\\hat Y_i)\n",
    "$$\n",
    "\n",
    "* $CE$ is low if prediction is good\n",
    "* $Y$ is one-hot encoded\n",
    "* $\\hat Y$ are probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy softmax: [0.65900114 0.24243297 0.09856589]\n",
      "Torch softmax: tensor([0.6590, 0.2424, 0.0986], dtype=torch.float64)\n",
      "Loss1 numpy: 0.3567\n",
      "Loss2 numpy: 2.3026\n",
      "Loss1 torch: 0.3018\n",
      "Loss2 torch: 1.6242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([2, 0, 1]), tensor([0, 2, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss  # / float(predicted.shape[0])\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "print(\"Numpy softmax:\", softmax(x))\n",
    "\n",
    "x = torch.from_numpy(x)\n",
    "print(\"Torch softmax:\", torch.softmax(x, dim=0))\n",
    "\n",
    "# Y must be one hot encoded\n",
    "# if class 0: [1 0 0]\n",
    "# if class 1: [0 1 0]\n",
    "# if class 2: [0 0 1]\n",
    "Y = np.array([1, 0, 0])\n",
    "\n",
    "# Y_pred has probabilities\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "\n",
    "print(f\"Loss1 numpy: {l1:.4f}\")\n",
    "print(f\"Loss2 numpy: {l2:.4f}\")\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([2, 0, 1])\n",
    "# nsamples * nclasses = 3*3\n",
    "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
    " \n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(f\"Loss1 torch: {l1.item():.4f}\")\n",
    "print(f\"Loss2 torch: {l2.item():.4f}\")\n",
    "\n",
    "_, prediction1 = torch.max(Y_pred_good, 1)\n",
    "_, prediction2 = torch.max(Y_pred_bad, 1)\n",
    "\n",
    "prediction1, prediction2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "* used to perform more complex tasks\n",
    "* else, it would be just a big linear regression model\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Step Function $f(x) = \\begin{align}\\begin{cases}1 & x \\ge 0 \\\\ 0 & x < 0\\end{cases}\\end{align}$\n",
    "* Sigmoid Function $f(x) = \\frac{1}{1+e^{-x}}$ -> Last layer in binary classification\n",
    "* TanH Function $f(x) = \\frac{2}{1+e^{-2x}} - 1$ -> hidden layer\n",
    "* ReLU $f(x) = max(0, x)$ -> hidden layers (default)\n",
    "* Leaky ReLU $f(x) = \\begin{align}\\begin{cases}x & x \\ge 0 \\\\ a*x & x < 0\\end{cases}\\end{align}$ -> solves vanishing gradient problem\n",
    "* Softmax $S(y_i) = \\frac{e^{y_i}}{\\sum e^{y_i}}$ -> Last layer in multi class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 (create nn modules)\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "# Option 2 (use activation functions directly in forward pass)\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device 'cuda'\n",
      "Epoch 1/2, step 100/600, loss = 0.5258\n",
      "Epoch 1/2, step 200/600, loss = 0.3907\n",
      "Epoch 1/2, step 300/600, loss = 0.2044\n",
      "Epoch 1/2, step 400/600, loss = 0.2055\n",
      "Epoch 1/2, step 500/600, loss = 0.3171\n",
      "Epoch 1/2, step 600/600, loss = 0.2231\n",
      "Epoch 2/2, step 100/600, loss = 0.2085\n",
      "Epoch 2/2, step 200/600, loss = 0.1962\n",
      "Epoch 2/2, step 300/600, loss = 0.2922\n",
      "Epoch 2/2, step 400/600, loss = 0.0787\n",
      "Epoch 2/2, step 500/600, loss = 0.1009\n",
      "Epoch 2/2, step 600/600, loss = 0.1933\n",
      "Accuracy = 95.63 %\n"
     ]
    }
   ],
   "source": [
    "input_size = 784  # 28x28 images\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "training_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=torchvision.transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# examples = iter(train_loader)\n",
    "# samples, labels = next(examples)\n",
    "\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2, 3, i+1)\n",
    "#     plt.imshow(samples[i][0], cmap=\"gray\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "print(f\"Using device '{device}'\")\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}\")\n",
    "\n",
    "# Test          \n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f\"Accuracy = {acc} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNN)\n",
    "\n",
    "Image classification using CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using device 'cuda'\n",
      "Epoch 1/4, step 2000/12500, loss = 2.2747\n",
      "Epoch 1/4, step 4000/12500, loss = 2.2853\n",
      "Epoch 1/4, step 6000/12500, loss = 2.3060\n",
      "Epoch 1/4, step 8000/12500, loss = 2.2679\n",
      "Epoch 1/4, step 10000/12500, loss = 2.2173\n",
      "Epoch 1/4, step 12000/12500, loss = 1.9701\n",
      "Epoch 2/4, step 2000/12500, loss = 1.7706\n",
      "Epoch 2/4, step 4000/12500, loss = 2.1498\n",
      "Epoch 2/4, step 6000/12500, loss = 2.1285\n",
      "Epoch 2/4, step 8000/12500, loss = 1.4128\n",
      "Epoch 2/4, step 10000/12500, loss = 1.6196\n",
      "Epoch 2/4, step 12000/12500, loss = 2.0395\n",
      "Epoch 3/4, step 2000/12500, loss = 2.0523\n",
      "Epoch 3/4, step 4000/12500, loss = 1.8692\n",
      "Epoch 3/4, step 6000/12500, loss = 0.7499\n",
      "Epoch 3/4, step 8000/12500, loss = 1.8559\n",
      "Epoch 3/4, step 10000/12500, loss = 1.7096\n",
      "Epoch 3/4, step 12000/12500, loss = 1.8108\n",
      "Epoch 4/4, step 2000/12500, loss = 1.7889\n",
      "Epoch 4/4, step 4000/12500, loss = 1.1546\n",
      "Epoch 4/4, step 6000/12500, loss = 1.8330\n",
      "Epoch 4/4, step 8000/12500, loss = 1.5774\n",
      "Epoch 4/4, step 10000/12500, loss = 1.6412\n",
      "Epoch 4/4, step 12000/12500, loss = 1.4843\n",
      "Finished Training\n",
      "Accuracy (Network) = 47.3 %\n",
      "Accuracy (Class plane) = 55.5 %\n",
      "Accuracy (Class car) = 75.5 %\n",
      "Accuracy (Class bird) = 25.9 %\n",
      "Accuracy (Class cat) = 28.8 %\n",
      "Accuracy (Class deer) = 26.7 %\n",
      "Accuracy (Class dog) = 51.2 %\n",
      "Accuracy (Class frog) = 62.4 %\n",
      "Accuracy (Class horse) = 55.2 %\n",
      "Accuracy (Class ship) = 49.2 %\n",
      "Accuracy (Class truck) = 42.6 %\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Dataset\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "training_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "# Network\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)  # 16*5*5 is the input size resulting from last pooling\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "print(f\"Using device '{device}'\")\n",
    "    \n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2000 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "        \n",
    "# Test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for _ in range(10)]\n",
    "    n_class_samples = [0 for _ in range(10)]\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            \n",
    "            if label == pred:\n",
    "                n_class_correct[label] += 1\n",
    "            \n",
    "            n_class_samples[label] += 1\n",
    "            \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f\"Accuracy (Network) = {acc} %\")\n",
    "    \n",
    "    for i in range(10):\n",
    "        acc = 100 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f\"Accuracy (Class {classes[i]}) = {acc} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
